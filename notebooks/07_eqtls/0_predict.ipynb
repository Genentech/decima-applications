{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict eQTL effects using Decima and Borzoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import os\n",
    "import tqdm\n",
    "import yaml\n",
    "\n",
    "from grelu.sequence.format import convert_input_type\n",
    "from grelu.sequence.utils import reverse_complement\n",
    "from grelu.transforms.prediction_transforms import get_compare_func, Aggregate, Specificity\n",
    "from grelu.data.preprocess import filter_blacklist, filter_chromosomes\n",
    "from grelu.variant import filter_variants\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, recall_score, accuracy_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to ensembl dict\n",
    "ensembl_out_dir = \"/gstore/data/resbioai/karollua/Decima/scborzoi/decima/results/ensemble\"\n",
    "with open(os.path.join(ensembl_out_dir,'ensembl_dict.yml'), 'r') as outfile:\n",
    "    ensembl_dict = yaml.safe_load(outfile)\n",
    "brozoi_out_dir = \"/gstore/data/resbioai/karollua/Decima/scborzoi/decima/results/brozoi\"\n",
    "brozoi_tracks_path = '/gstore/data/resbioai/karollua/Decima/scborzoi/decima/data/borzoi_targets/targets_human.txt'\n",
    "\n",
    "# anndata file\n",
    "anndata_file = \"/gstore/data/resbioai/grelu/decima/2024082/data.h5ad\"\n",
    "\n",
    "# path to gene h5\n",
    "h5_file = \"/gstore/data/resbioai/grelu/decima/20240823/data.h5\"\n",
    "\n",
    "# eqtl paths\n",
    "susie_dir = '/gstore/data/resbioai/grelu/decima/onek1k/susie/QTS000038' # QTS000038 is OneK1K study ID\n",
    "eqtl_sumstats_base_path = \"/gstore/data/resbioai/grelu/decima/onek1k/sumstats/*.all.tsv.gz\"\n",
    "\n",
    "# where to save results\n",
    "save_dir = \"/gstore/data/resbioai/karollua/Decima/scborzoi/decima/\"\n",
    "brozima_ensembl_out_dir = os.path.join(save_dir, \"results\", 'brozoi',f'brozima_unsquash_ensembl')\n",
    "\n",
    "# path for variants\n",
    "susie_df_file = os.path.join(save_dir,'data/eQTL_processed/susie_df.csv')\n",
    "variant_df_file = os.path.join(save_dir,'data/eQTL_processed/vars.csv')\n",
    "neg_variant_df_file = os.path.join(save_dir,'data/eQTL_processed/neg_vars_all.csv')\n",
    "matched_negative_file = os.path.join(save_dir,'data/eQTL_processed/matched_negative.csv')\n",
    "matched_negative_dedup_file = os.path.join(save_dir,'data/eQTL_processed/matched_negative_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = anndata.read_h5ad(anndata_file)\n",
    "brozoi_tracks = pd.read_csv(brozoi_tracks_path,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download eQTL metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtl_meta = pd.read_table('https://raw.githubusercontent.com/eQTL-Catalogue/eQTL-Catalogue-resources/master/data_tables/dataset_metadata.tsv')\n",
    "eqtl_meta = eqtl_meta[eqtl_meta.quant_method == 'ge'] # gene exp. QTLs\n",
    "eqtl_meta = eqtl_meta[eqtl_meta.study_label == 'OneK1K'] # Yazar et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dict = eqtl_meta[['dataset_id', 'tissue_label']].set_index('dataset_id').to_dict()['tissue_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuSiE (in)credible sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -r -e robots=off -P /home/karollua/projects/Decima/scborzoi/AKv1/data/eQTL https://ftp.ebi.ac.uk/pub/databases/spot/eQTL/susie/QTS000038 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_id_map = ad.var[['gene_id']].reset_index().set_index('gene_id')['index'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susie_df = []\n",
    "\n",
    "for ct_id in tqdm.tqdm(list(ct_dict.keys())):\n",
    "    df = pd.read_table(f'{susie_dir}/{ct_id}/{ct_id}.credible_sets.tsv.gz')\n",
    "    df['chrom'] = [x.split('_')[0] for x in df.variant]\n",
    "    df['pos'] = [int(x.split('_')[1]) for x in df.variant]\n",
    "    df['ref'] = [x.split('_')[2] for x in df.variant]\n",
    "    df['alt'] = [x.split('_')[3] for x in df.variant]\n",
    "    df['gene_symbol'] = df.gene_id.map(ensembl_id_map)\n",
    "\n",
    "    susie_df.append(df.assign(celltype=ct_dict[ct_id], celltype_id=ct_id))\n",
    "\n",
    "susie_df = pd.concat(susie_df, axis=0).reset_index(drop=True)\n",
    "susie_df.head()\n",
    "\n",
    "# make complete list of \"credible variants\"\n",
    "cs_vars = set(susie_df['variant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susie_df = susie_df[susie_df.gene_symbol.notna()]\n",
    "susie_df = filter_variants(susie_df, max_del_len=0, max_insert_len=0, standard_bases=True) # remove indels\n",
    "susie_df = filter_chromosomes(susie_df, include='autosomesXY') # keep standard chroms\n",
    "susie_df = filter_blacklist(susie_df, genome=\"hg38\", window=100) # remove variants in blacklisted regions\n",
    "\n",
    "# add gene information and calculate relative variant positions (offset)\n",
    "susie_df = susie_df.merge(ad.var[['gene_id', 'start', 'end', 'strand', 'gene_mask_start']]).rename(columns={'start': 'gene_window_start', 'end': 'gene_window_end', 'strand': 'gene_strand'}) # add window information\n",
    "susie_df = susie_df[((susie_df.pos > susie_df.gene_window_start) & (susie_df.pos < susie_df.gene_window_end))] # keep variants within the sequence window\n",
    "susie_df['pos_relative'] = susie_df.pos - susie_df.gene_window_start - 1\n",
    "\n",
    "# use gene_end to calculate offset for - genes and rc() alleles\n",
    "susie_df.loc[susie_df.gene_strand=='-', 'pos_relative'] = susie_df.gene_window_end[susie_df.gene_strand=='-'] - susie_df.pos[susie_df.gene_strand=='-']\n",
    "susie_df.loc[susie_df.gene_strand=='-', 'ref'] = [reverse_complement(x) for x in susie_df.loc[susie_df.gene_strand=='-', 'ref']]\n",
    "susie_df.loc[susie_df.gene_strand=='-', 'alt'] = [reverse_complement(x) for x in susie_df.loc[susie_df.gene_strand=='-', 'alt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susie_df['pos_rel_TSS'] = susie_df[\"pos_relative\"] - susie_df[\"gene_mask_start\"]\n",
    "susie_df['abspos_rel_TSS'] = np.abs(susie_df['pos_rel_TSS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in negatives from non-finemapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each gene, we need boundaries, to exclude \"unseeable\" stuff\n",
    "gene_to_boundary_dict = {v.gene_id:{'chr':v.chrom,'start':v.start,'end':v.end, 'strand':v.strand} for k,v in ad.var.iterrows()}\n",
    "def check_scoreability(row):\n",
    "    if row['gene_id'] not in gene_to_boundary_dict:\n",
    "        return False\n",
    "    boundary = gene_to_boundary_dict[row['gene_id']]\n",
    "    pos = row['position']\n",
    "    gene_window_start = boundary['start']\n",
    "    gene_window_end = boundary['end']\n",
    "    return (pos > gene_window_start) & (pos < gene_window_end)\n",
    "\n",
    "# get all genes which have *some* positive\n",
    "pos_genes = set(susie_df.query('pip > 0.5')['gene_id'])\n",
    "high_pos_genes = set(susie_df.query('pip > 0.9')['gene_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_list = []\n",
    "\n",
    "dtype_list = [np.dtype('O'),np.dtype('O'),np.dtype('int64'),np.dtype('O'),np.dtype('O'),np.dtype('O'),np.dtype('int64'),np.dtype('float64'),np.dtype('float64'),np.dtype('float64'),np.dtype('float64'),np.dtype('O'),np.dtype('int64'),np.dtype('int64'),np.dtype('float64'),np.dtype('O'),np.dtype('O'),np.dtype('float64'),np.dtype('O')]\n",
    "names = ['molecular_trait_id', 'chromosome', 'position', 'ref', 'alt', 'variant','ma_samples', 'maf', 'pvalue', 'beta', 'se', 'type', 'ac', 'an', 'r2','molecular_trait_object_id', 'gene_id', 'median_tpm', 'rsid']\n",
    "dtype_dict = {k:v for k,v in zip(names,dtype_list)}\n",
    "\n",
    "negvar_paths = glob.glob(eqtl_sumstats_base_path)\n",
    "for path in tqdm.tqdm(negvar_paths):\n",
    "    negvar_df = pd.read_csv(path, sep=\"\\t\", dtype=dtype_dict)\n",
    "    negvar_select = negvar_df.query('pvalue > 0.05 and type == \"SNP\" and maf > 0.05') # pre-select nonsignificant\n",
    "    negvar_select = negvar_select.loc[negvar_select.gene_id.isin(pos_genes)] # consider only genes with some positive\n",
    "    negvar_select = negvar_select.loc[~negvar_select.variant.isin(cs_vars)] # collect everything which never enters *any* credible set\n",
    "    negvar_select = negvar_select.loc[negvar_select.apply(lambda row: check_scoreability(row), axis=1)] # check if they are in the right window\n",
    "    negvar_select['ct_id'] = path.split('/')[-1].split('.')[0]\n",
    "    negvar_list.append(negvar_select)\n",
    "    del negvar_df\n",
    "\n",
    "negvar_all = pd.concat(negvar_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_all['celltype'] = negvar_all['ct_id'].apply(lambda x: ct_dict[x])\n",
    "\n",
    "# for each negative, compute the relpos and distance to the TSS \n",
    "negvar_dedup = negvar_all[['gene_id','variant','position','ref','alt']].drop_duplicates()\n",
    "\n",
    "# add gene information and calculate relative variant positions (offset)\n",
    "negvar_dedup = negvar_dedup.merge(ad.var[['gene_id', 'start', 'end', 'strand', 'gene_mask_start']]).rename(columns={'start': 'gene_window_start', 'end': 'gene_window_end', 'strand': 'gene_strand'}) # add window information\n",
    "negvar_dedup['pos_relative'] = negvar_dedup.position - negvar_dedup.gene_window_start - 1\n",
    "\n",
    "# use gene_end to calculate offset for - genes and rc() alleles\n",
    "negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'pos_relative'] = negvar_dedup.gene_window_end[negvar_dedup.gene_strand=='-'] - negvar_dedup.position[negvar_dedup.gene_strand=='-']\n",
    "negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'ref'] = [reverse_complement(x) for x in negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'ref']]\n",
    "negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'alt'] = [reverse_complement(x) for x in negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'alt']]\n",
    "\n",
    "negvar_dedup['pos_rel_TSS'] = negvar_dedup[\"pos_relative\"] - negvar_dedup['gene_mask_start']\n",
    "negvar_dedup['abspos_rel_TSS'] = np.abs(negvar_dedup['pos_rel_TSS'])\n",
    "\n",
    "negvar_all = negvar_all.drop(columns=['ref','alt']).merge(negvar_dedup[['gene_id','variant','gene_strand','ref','alt',\"pos_relative\",\"pos_rel_TSS\",\"abspos_rel_TSS\"]],on=['gene_id','variant'])\n",
    "negvar_all.to_csv(neg_variant_df_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_all.to_csv(neg_variant_df_file, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched = negvar_all.loc[negvar_all.gene_id.isin(high_pos_genes)]\n",
    "negvar_matched['gene_symbol'] = negvar_matched.gene_id.map(ensembl_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each positive variant, collect target_negative_n negatives wich are as close to the TSS as possible, and not yet selected for this cell-type\n",
    "target_negative_n = 20\n",
    "selected_vars = {}\n",
    "for celltype in tqdm.tqdm(set(susie_df['celltype'])):\n",
    "    positive_df = susie_df.query('pip > 0.9 & celltype == @celltype')\n",
    "    negative_df = negvar_matched.query('celltype == @celltype')#.loc[negvar_matched.gene_id.isin(set(positive_df['gene_id']))]\n",
    "    selected_vars[celltype] = set()\n",
    "    for _,positive in positive_df.iterrows():\n",
    "        negative_sub = negative_df.loc[(negative_df.gene_id == positive['gene_id'])]\n",
    "        negative_sub = negative_sub.sort_values('abspos_rel_TSS')\n",
    "        i = 0\n",
    "        for _,variant in negative_sub.iterrows():\n",
    "            if variant['variant'] not in selected_vars[celltype]:\n",
    "                selected_vars[celltype].add(variant['variant'])\n",
    "                i += 1\n",
    "                if i == target_negative_n:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for celltype in selected_vars:\n",
    "    rows.append({'celltype':celltype, \n",
    "                 'pos_genes':len(set(susie_df.query('pip > 0.9 & celltype == @celltype')['gene_symbol'])),\n",
    "                 'pos_genes_with_neg_ct':len(set(negvar_matched.query('celltype == @celltype')['gene_symbol']) & set(susie_df.query('pip > 0.9 & celltype == @celltype')['gene_symbol'])),\n",
    "                 'total_pos':len(set(susie_df.query('pip > 0.9 & celltype == @celltype')['variant'])),\n",
    "                 'total_matched_neg':len(set(negvar_matched.query('celltype == @celltype').merge(susie_df.query('pip > 0.9 & celltype == @celltype')['gene_id'],on='gene_id')['variant'])),\n",
    "                 'reduced_matched_neg':len(selected_vars[celltype]),\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched_reduced = pd.concat([negvar_matched.loc[negvar_matched.variant.isin(selected_vars[celltype]) & (negvar_matched.celltype == celltype)] for celltype in selected_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched_dedup = negvar_matched_reduced[['gene_symbol','gene_id','variant','position','ref','alt','gene_strand','pos_relative']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched_reduced.to_csv(matched_negative_file ,index=None)\n",
    "negvar_matched_dedup.to_csv(matched_negative_dedup_file ,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble Variant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all finemapped and matched negatives for all celltypes\n",
    "negvar_matched_reduced['pip'] = 0\n",
    "negvar_matched_reduced['cs_id'] = 'negative'\n",
    "negvar_matched_reduced['cs_size'] = 0\n",
    "negvar_matched_reduced = negvar_matched_reduced.rename(columns={'ct_id':'celltype_id',\n",
    "                                                                'chromosome':'chrom',\n",
    "                                                                'position':'pos',\n",
    "                                                                })\n",
    "negvar_matched_reduced = negvar_matched_reduced.drop(columns=['ac','an','ma_samples','maf','median_tpm','molecular_trait_object_id','r2','type'])\n",
    "susie_df = susie_df.drop(columns=['cs_min_r2','region','z','gene_window_start','gene_window_end'])\n",
    "susie_df = pd.concat([susie_df, negvar_matched_reduced])\n",
    "susie_df.to_csv(susie_df_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_df = susie_df[['gene_id', 'gene_symbol', 'variant', 'rsid', 'chrom', 'pos', 'ref', 'alt', 'gene_strand', 'pos_relative']].drop_duplicates(subset=['gene_id','variant'])\n",
    "variant_df.to_csv(variant_df_file,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict variant effects with Decima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 8\n",
    "df_len = len(variant_df)\n",
    "job_size = math.ceil(df_len / n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckpt_file in ckpt_files:\n",
    "    for i in range(8):\n",
    "       predict_script = \"PredicteQTL.py\"\n",
    "       cmd = f\"python {predict_script} -device {i} -task {i} -job_size {job_size} \\\n",
    "-ckpt_file {ckpt_file} -gene_h5_file {h5_file} -variant_df_file {variant_df_file} \\\n",
    "-out_dir {results_path}\"\n",
    "       print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble the Decima scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtl_ensembl_dict = collections.defaultdict(list)\n",
    "starts = set()\n",
    "ends = set()\n",
    "for k in tqdm.tqdm(ensembl_dict):\n",
    "    if k.startswith('test'):    \n",
    "        run_id = ensembl_dict[k]['run_id']\n",
    "        eqtl_results_path = os.path.join(save_dir, \"results\", run_id,'eqtl','eqtl_scores_*')\n",
    "        pred_paths = sorted(glob.glob(os.path.join(eqtl_results_path)), key=lambda x: int(x.split('/')[-1].split(\"_\")[2]))\n",
    "        for i,pred in enumerate(pred_paths):\n",
    "            preds = np.load(pred)\n",
    "            starts.add(int(pred.split('/')[-1].split(\"_\")[2]))\n",
    "            ends.add(int(pred.split('/')[-1].split('.')[0].split(\"_\")[3]))\n",
    "            eqtl_ensembl_dict[i].append(preds)\n",
    "assert len(eqtl_ensembl_dict) == n_jobs\n",
    "ensembl_eqtl_out_dir = os.path.join(ensembl_out_dir,'eqtl'+suffix)\n",
    "if not os.path.exists(ensembl_eqtl_out_dir):\n",
    "    os.mkdir(ensembl_eqtl_out_dir)\n",
    "starts = sorted(list(starts))\n",
    "ends = sorted(list(ends))\n",
    "for i in range(8):\n",
    "    start = starts[i]\n",
    "    end = ends[i]\n",
    "    mean_pred = np.stack(eqtl_ensembl_dict[i]).mean(0)\n",
    "    np.save(os.path.join(ensembl_eqtl_out_dir,f'eqtl_scores_{start}_{end}'), mean_pred)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict variant effects using Borzoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in tqdm.tqdm([0,1,2,3]):\n",
    "    for i in range(8):\n",
    "       cmd = f\"python Borzoi.py -device {i} -task {i} -job_size {job_size} -tracks {brozoi_tracks_path} -unsquash \\\n",
    "-fold {fold} -gene_h5_file {h5_file} -variant_df_file {variant_df_file} -out_dir {brozoi_out_dir}\"\n",
    "       print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Borzoi predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score_type in ['gene', 'tss']:\n",
    "    brozima_ensembl_dict = collections.defaultdict(list)\n",
    "    starts = set()\n",
    "    ends = set()\n",
    "    for fold in tqdm.tqdm([0,1,2,3]):\n",
    "        eqtl_results_path = os.path.join(save_dir, \"results\", 'brozoi',f'brozima_fold{fold}_unsquash',f'{score_type}_scores_*')\n",
    "        pred_paths = sorted(glob.glob(os.path.join(eqtl_results_path)), key=lambda x: int(x.split('/')[-1].split(\"_\")[2]))\n",
    "        for i,pred in enumerate(pred_paths):\n",
    "            preds = np.load(pred)\n",
    "            starts.add(int(pred.split('/')[-1].split(\"_\")[2]))\n",
    "            ends.add(int(pred.split('/')[-1].split('.')[0].split(\"_\")[3]))\n",
    "            brozima_ensembl_dict[i].append(preds)\n",
    "    assert len(brozima_ensembl_dict) == n_jobs\n",
    "    brozima_ensembl_eqtl_out_dir = os.path.join(save_dir, \"results\", 'brozoi',f'brozima_eqtl_unsquash_ensembl')\n",
    "    if not os.path.exists(brozima_ensembl_eqtl_out_dir):\n",
    "        os.mkdir(brozima_ensembl_eqtl_out_dir)\n",
    "    starts = sorted(list(starts))\n",
    "    ends = sorted(list(ends))\n",
    "    for i in range(8):\n",
    "        start = starts[i]\n",
    "        end = ends[i]\n",
    "        mean_pred = np.stack(brozima_ensembl_dict[i]).mean(0)\n",
    "        np.save(os.path.join(brozima_ensembl_eqtl_out_dir,f'{score_type}_scores_{start}_{end}'), mean_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
