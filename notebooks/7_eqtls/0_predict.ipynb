{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import collections\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import os\n",
    "import tqdm\n",
    "import yaml\n",
    "import wandb\n",
    "\n",
    "from grelu.sequence.format import convert_input_type\n",
    "from grelu.sequence.utils import reverse_complement\n",
    "from grelu.transforms.prediction_transforms import get_compare_func, Aggregate, Specificity\n",
    "from grelu.data.preprocess import filter_blacklist, filter_chromosomes\n",
    "from grelu.variant import filter_variants\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, recall_score, accuracy_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to ensembl dict\n",
    "ensembl_out_dir = \"/gstore/data/resbioai/karollua/Decima/scborzoi/decima/results/ensemble\"\n",
    "with open(os.path.join(ensembl_out_dir,'ensembl_dict.yml'), 'r') as outfile:\n",
    "    ensembl_dict = yaml.safe_load(outfile)\n",
    "brozoi_out_dir = \"/gstore/data/resbioai/karollua/Decima/scborzoi/decima/results/brozoi\"\n",
    "brozoi_tracks_path = '/gstore/data/resbioai/karollua/Decima/scborzoi/decima/data/borzoi_targets/targets_human.txt'\n",
    "\n",
    "# anndata file\n",
    "anndata_file = \"/gstore/data/resbioai/grelu/decima/2024082/data.h5ad\"\n",
    "\n",
    "# path to gene h5\n",
    "h5_file = \"/gstore/data/resbioai/grelu/decima/20240823/data.h5\"\n",
    "\n",
    "# eqtl paths\n",
    "susie_dir = '/gstore/data/resbioai/grelu/decima/onek1k/susie/QTS000038' # QTS000038 is OneK1K study ID\n",
    "eqtl_sumstats_base_path = \"/gstore/data/resbioai/grelu/decima/onek1k/sumstats/*.all.tsv.gz\"\n",
    "\n",
    "# where to save results\n",
    "save_dir = \"/gstore/data/resbioai/karollua/Decima/scborzoi/decima/\"\n",
    "brozima_ensembl_out_dir = os.path.join(save_dir, \"results\", 'brozoi',f'brozima_unsquash_ensembl')\n",
    "\n",
    "# path for variants\n",
    "susie_df_file = os.path.join(save_dir,'data/eQTL_processed/susie_df.csv')\n",
    "variant_df_file = os.path.join(save_dir,'data/eQTL_processed/vars.csv')\n",
    "neg_variant_df_file = os.path.join(save_dir,'data/eQTL_processed/neg_vars_all.csv')\n",
    "matched_negative_file = os.path.join(save_dir,'data/eQTL_processed/matched_negative.csv')\n",
    "matched_negative_dedup_file = os.path.join(save_dir,'data/eQTL_processed/matched_negative_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = anndata.read_h5ad(anndata_file)\n",
    "brozoi_tracks = pd.read_csv(brozoi_tracks_path,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download eQTL metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtl_meta = pd.read_table('https://raw.githubusercontent.com/eQTL-Catalogue/eQTL-Catalogue-resources/master/data_tables/dataset_metadata.tsv')\n",
    "eqtl_meta = eqtl_meta[eqtl_meta.quant_method == 'ge'] # gene exp. QTLs\n",
    "eqtl_meta = eqtl_meta[eqtl_meta.study_label == 'OneK1K'] # Yazar et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dict = eqtl_meta[['dataset_id', 'tissue_label']].set_index('dataset_id').to_dict()['tissue_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuSiE (in)credible sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -r -e robots=off -P /home/karollua/projects/Decima/scborzoi/AKv1/data/eQTL https://ftp.ebi.ac.uk/pub/databases/spot/eQTL/susie/QTS000038 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_id_map = ad.var[['gene_id']].reset_index().set_index('gene_id')['index'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susie_df = []\n",
    "\n",
    "for ct_id in tqdm.tqdm(list(ct_dict.keys())):\n",
    "    df = pd.read_table(f'{susie_dir}/{ct_id}/{ct_id}.credible_sets.tsv.gz')\n",
    "    df['chrom'] = [x.split('_')[0] for x in df.variant]\n",
    "    df['pos'] = [int(x.split('_')[1]) for x in df.variant]\n",
    "    df['ref'] = [x.split('_')[2] for x in df.variant]\n",
    "    df['alt'] = [x.split('_')[3] for x in df.variant]\n",
    "    df['gene_symbol'] = df.gene_id.map(ensembl_id_map)\n",
    "\n",
    "    susie_df.append(df.assign(celltype=ct_dict[ct_id], celltype_id=ct_id))\n",
    "\n",
    "susie_df = pd.concat(susie_df, axis=0).reset_index(drop=True)\n",
    "susie_df.head()\n",
    "\n",
    "# make complete list of \"credible variants\"\n",
    "cs_vars = set(susie_df['variant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susie_df = susie_df[susie_df.gene_symbol.notna()]\n",
    "susie_df = filter_variants(susie_df, max_del_len=0, max_insert_len=0, standard_bases=True) # remove indels\n",
    "susie_df = filter_chromosomes(susie_df, include='autosomesXY') # keep standard chroms\n",
    "susie_df = filter_blacklist(susie_df, genome=\"hg38\", window=100) # remove variants in blacklisted regions\n",
    "\n",
    "# add gene information and calculate relative variant positions (offset)\n",
    "susie_df = susie_df.merge(ad.var[['gene_id', 'start', 'end', 'strand', 'gene_mask_start']]).rename(columns={'start': 'gene_window_start', 'end': 'gene_window_end', 'strand': 'gene_strand'}) # add window information\n",
    "susie_df = susie_df[((susie_df.pos > susie_df.gene_window_start) & (susie_df.pos < susie_df.gene_window_end))] # keep variants within the sequence window\n",
    "susie_df['pos_relative'] = susie_df.pos - susie_df.gene_window_start - 1\n",
    "\n",
    "# use gene_end to calculate offset for - genes and rc() alleles\n",
    "susie_df.loc[susie_df.gene_strand=='-', 'pos_relative'] = susie_df.gene_window_end[susie_df.gene_strand=='-'] - susie_df.pos[susie_df.gene_strand=='-']\n",
    "susie_df.loc[susie_df.gene_strand=='-', 'ref'] = [reverse_complement(x) for x in susie_df.loc[susie_df.gene_strand=='-', 'ref']]\n",
    "susie_df.loc[susie_df.gene_strand=='-', 'alt'] = [reverse_complement(x) for x in susie_df.loc[susie_df.gene_strand=='-', 'alt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susie_df['pos_rel_TSS'] = susie_df[\"pos_relative\"] - susie_df[\"gene_mask_start\"]\n",
    "susie_df['abspos_rel_TSS'] = np.abs(susie_df['pos_rel_TSS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in negatives from non-finemapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each gene, we need boundaries, to exclude \"unseeable\" stuff\n",
    "gene_to_boundary_dict = {v.gene_id:{'chr':v.chrom,'start':v.start,'end':v.end, 'strand':v.strand} for k,v in ad.var.iterrows()}\n",
    "def check_scoreability(row):\n",
    "    if row['gene_id'] not in gene_to_boundary_dict:\n",
    "        return False\n",
    "    boundary = gene_to_boundary_dict[row['gene_id']]\n",
    "    pos = row['position']\n",
    "    gene_window_start = boundary['start']\n",
    "    gene_window_end = boundary['end']\n",
    "    return (pos > gene_window_start) & (pos < gene_window_end)\n",
    "\n",
    "# get all genes which have *some* positive\n",
    "pos_genes = set(susie_df.query('pip > 0.5')['gene_id'])\n",
    "high_pos_genes = set(susie_df.query('pip > 0.9')['gene_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_list = []\n",
    "\n",
    "dtype_list = [np.dtype('O'),np.dtype('O'),np.dtype('int64'),np.dtype('O'),np.dtype('O'),np.dtype('O'),np.dtype('int64'),np.dtype('float64'),np.dtype('float64'),np.dtype('float64'),np.dtype('float64'),np.dtype('O'),np.dtype('int64'),np.dtype('int64'),np.dtype('float64'),np.dtype('O'),np.dtype('O'),np.dtype('float64'),np.dtype('O')]\n",
    "names = ['molecular_trait_id', 'chromosome', 'position', 'ref', 'alt', 'variant','ma_samples', 'maf', 'pvalue', 'beta', 'se', 'type', 'ac', 'an', 'r2','molecular_trait_object_id', 'gene_id', 'median_tpm', 'rsid']\n",
    "dtype_dict = {k:v for k,v in zip(names,dtype_list)}\n",
    "\n",
    "negvar_paths = glob.glob(eqtl_sumstats_base_path)\n",
    "for path in tqdm.tqdm(negvar_paths):\n",
    "    negvar_df = pd.read_csv(path, sep=\"\\t\", dtype=dtype_dict)\n",
    "    negvar_select = negvar_df.query('pvalue > 0.05 and type == \"SNP\" and maf > 0.05') # pre-select nonsignificant\n",
    "    negvar_select = negvar_select.loc[negvar_select.gene_id.isin(pos_genes)] # consider only genes with some positive\n",
    "    negvar_select = negvar_select.loc[~negvar_select.variant.isin(cs_vars)] # collect everything which never enters *any* credible set\n",
    "    negvar_select = negvar_select.loc[negvar_select.apply(lambda row: check_scoreability(row), axis=1)] # check if they are in the right window\n",
    "    negvar_select['ct_id'] = path.split('/')[-1].split('.')[0]\n",
    "    negvar_list.append(negvar_select)\n",
    "    del negvar_df\n",
    "\n",
    "negvar_all = pd.concat(negvar_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_all['celltype'] = negvar_all['ct_id'].apply(lambda x: ct_dict[x])\n",
    "\n",
    "# for each negative, compute the relpos and distance to the TSS \n",
    "negvar_dedup = negvar_all[['gene_id','variant','position','ref','alt']].drop_duplicates()\n",
    "\n",
    "# add gene information and calculate relative variant positions (offset)\n",
    "negvar_dedup = negvar_dedup.merge(ad.var[['gene_id', 'start', 'end', 'strand', 'gene_mask_start']]).rename(columns={'start': 'gene_window_start', 'end': 'gene_window_end', 'strand': 'gene_strand'}) # add window information\n",
    "negvar_dedup['pos_relative'] = negvar_dedup.position - negvar_dedup.gene_window_start - 1\n",
    "\n",
    "# use gene_end to calculate offset for - genes and rc() alleles\n",
    "negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'pos_relative'] = negvar_dedup.gene_window_end[negvar_dedup.gene_strand=='-'] - negvar_dedup.position[negvar_dedup.gene_strand=='-']\n",
    "negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'ref'] = [reverse_complement(x) for x in negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'ref']]\n",
    "negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'alt'] = [reverse_complement(x) for x in negvar_dedup.loc[negvar_dedup.gene_strand=='-', 'alt']]\n",
    "\n",
    "negvar_dedup['pos_rel_TSS'] = negvar_dedup[\"pos_relative\"] - negvar_dedup['gene_mask_start']\n",
    "negvar_dedup['abspos_rel_TSS'] = np.abs(negvar_dedup['pos_rel_TSS'])\n",
    "\n",
    "negvar_all = negvar_all.drop(columns=['ref','alt']).merge(negvar_dedup[['gene_id','variant','gene_strand','ref','alt',\"pos_relative\",\"pos_rel_TSS\",\"abspos_rel_TSS\"]],on=['gene_id','variant'])\n",
    "negvar_all.to_csv(neg_variant_df_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_all.to_csv(neg_variant_df_file, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched = negvar_all.loc[negvar_all.gene_id.isin(high_pos_genes)]\n",
    "negvar_matched['gene_symbol'] = negvar_matched.gene_id.map(ensembl_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each positive variant, collect target_negative_n negatives wich are as close to the TSS as possible, and not yet selected for this cell-type\n",
    "target_negative_n = 20\n",
    "selected_vars = {}\n",
    "for celltype in tqdm.tqdm(set(susie_df['celltype'])):\n",
    "    positive_df = susie_df.query('pip > 0.9 & celltype == @celltype')\n",
    "    negative_df = negvar_matched.query('celltype == @celltype')#.loc[negvar_matched.gene_id.isin(set(positive_df['gene_id']))]\n",
    "    selected_vars[celltype] = set()\n",
    "    for _,positive in positive_df.iterrows():\n",
    "        negative_sub = negative_df.loc[(negative_df.gene_id == positive['gene_id'])]\n",
    "        negative_sub = negative_sub.sort_values('abspos_rel_TSS')\n",
    "        i = 0\n",
    "        for _,variant in negative_sub.iterrows():\n",
    "            if variant['variant'] not in selected_vars[celltype]:\n",
    "                selected_vars[celltype].add(variant['variant'])\n",
    "                i += 1\n",
    "                if i == target_negative_n:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for celltype in selected_vars:\n",
    "    rows.append({'celltype':celltype, \n",
    "                 'pos_genes':len(set(susie_df.query('pip > 0.9 & celltype == @celltype')['gene_symbol'])),\n",
    "                 'pos_genes_with_neg_ct':len(set(negvar_matched.query('celltype == @celltype')['gene_symbol']) & set(susie_df.query('pip > 0.9 & celltype == @celltype')['gene_symbol'])),\n",
    "                 'total_pos':len(set(susie_df.query('pip > 0.9 & celltype == @celltype')['variant'])),\n",
    "                 'total_matched_neg':len(set(negvar_matched.query('celltype == @celltype').merge(susie_df.query('pip > 0.9 & celltype == @celltype')['gene_id'],on='gene_id')['variant'])),\n",
    "                 'reduced_matched_neg':len(selected_vars[celltype]),\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched_reduced = pd.concat([negvar_matched.loc[negvar_matched.variant.isin(selected_vars[celltype]) & (negvar_matched.celltype == celltype)] for celltype in selected_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched_dedup = negvar_matched_reduced[['gene_symbol','gene_id','variant','position','ref','alt','gene_strand','pos_relative']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negvar_matched_reduced.to_csv(matched_negative_file ,index=None)\n",
    "negvar_matched_dedup.to_csv(matched_negative_dedup_file ,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble Variant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all finemapped and matched negatives for all celltypes\n",
    "negvar_matched_reduced['pip'] = 0\n",
    "negvar_matched_reduced['cs_id'] = 'negative'\n",
    "negvar_matched_reduced['cs_size'] = 0\n",
    "negvar_matched_reduced = negvar_matched_reduced.rename(columns={'ct_id':'celltype_id',\n",
    "                                                                'chromosome':'chrom',\n",
    "                                                                'position':'pos',\n",
    "                                                                })\n",
    "negvar_matched_reduced = negvar_matched_reduced.drop(columns=['ac','an','ma_samples','maf','median_tpm','molecular_trait_object_id','r2','type'])\n",
    "susie_df = susie_df.drop(columns=['cs_min_r2','region','z','gene_window_start','gene_window_end'])\n",
    "susie_df = pd.concat([susie_df, negvar_matched_reduced])\n",
    "susie_df.to_csv(susie_df_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_df = susie_df[['gene_id', 'gene_symbol', 'variant', 'rsid', 'chrom', 'pos', 'ref', 'alt', 'gene_strand', 'pos_relative']].drop_duplicates(subset=['gene_id','variant'])\n",
    "variant_df.to_csv(variant_df_file,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict variant effects with Decima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 8\n",
    "df_len = len(variant_df)\n",
    "job_size = math.ceil(df_len / n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckpt_file in ckpt_files:\n",
    "    for i in range(8):\n",
    "       predict_script = \"PredicteQTL.py\"\n",
    "       cmd = f\"python {predict_script} -device {i} -task {i} -job_size {job_size} \\\n",
    "-ckpt_file {ckpt_file} -gene_h5_file {h5_file} -variant_df_file {variant_df_file} \\\n",
    "-out_dir {results_path}\"\n",
    "       print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble the Decima scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtl_ensembl_dict = collections.defaultdict(list)\n",
    "starts = set()\n",
    "ends = set()\n",
    "for k in tqdm.tqdm(ensembl_dict):\n",
    "    if k.startswith('test'):    \n",
    "        run_id = ensembl_dict[k]['run_id']\n",
    "        eqtl_results_path = os.path.join(save_dir, \"results\", run_id,'eqtl','eqtl_scores_*')\n",
    "        pred_paths = sorted(glob.glob(os.path.join(eqtl_results_path)), key=lambda x: int(x.split('/')[-1].split(\"_\")[2]))\n",
    "        for i,pred in enumerate(pred_paths):\n",
    "            preds = np.load(pred)\n",
    "            starts.add(int(pred.split('/')[-1].split(\"_\")[2]))\n",
    "            ends.add(int(pred.split('/')[-1].split('.')[0].split(\"_\")[3]))\n",
    "            eqtl_ensembl_dict[i].append(preds)\n",
    "assert len(eqtl_ensembl_dict) == n_jobs\n",
    "ensembl_eqtl_out_dir = os.path.join(ensembl_out_dir,'eqtl'+suffix)\n",
    "if not os.path.exists(ensembl_eqtl_out_dir):\n",
    "    os.mkdir(ensembl_eqtl_out_dir)\n",
    "starts = sorted(list(starts))\n",
    "ends = sorted(list(ends))\n",
    "for i in range(8):\n",
    "    start = starts[i]\n",
    "    end = ends[i]\n",
    "    mean_pred = np.stack(eqtl_ensembl_dict[i]).mean(0)\n",
    "    np.save(os.path.join(ensembl_eqtl_out_dir,f'eqtl_scores_{start}_{end}'), mean_pred)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict variant effects using Borzoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in tqdm.tqdm([0,1,2,3]):\n",
    "    for i in range(8):\n",
    "       cmd = f\"python Borzoi.py -device {i} -task {i} -job_size {job_size} -tracks {brozoi_tracks_path} -unsquash \\\n",
    "-fold {fold} -gene_h5_file {h5_file} -variant_df_file {variant_df_file} -out_dir {brozoi_out_dir}\"\n",
    "       print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Borzoi predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score_type in ['gene', 'tss']:\n",
    "    brozima_ensembl_dict = collections.defaultdict(list)\n",
    "    starts = set()\n",
    "    ends = set()\n",
    "    for fold in tqdm.tqdm([0,1,2,3]):\n",
    "        eqtl_results_path = os.path.join(save_dir, \"results\", 'brozoi',f'brozima_fold{fold}_unsquash',f'{score_type}_scores_*')\n",
    "        pred_paths = sorted(glob.glob(os.path.join(eqtl_results_path)), key=lambda x: int(x.split('/')[-1].split(\"_\")[2]))\n",
    "        for i,pred in enumerate(pred_paths):\n",
    "            preds = np.load(pred)\n",
    "            starts.add(int(pred.split('/')[-1].split(\"_\")[2]))\n",
    "            ends.add(int(pred.split('/')[-1].split('.')[0].split(\"_\")[3]))\n",
    "            brozima_ensembl_dict[i].append(preds)\n",
    "    assert len(brozima_ensembl_dict) == n_jobs\n",
    "    brozima_ensembl_eqtl_out_dir = os.path.join(save_dir, \"results\", 'brozoi',f'brozima_eqtl_unsquash_ensembl')\n",
    "    if not os.path.exists(brozima_ensembl_eqtl_out_dir):\n",
    "        os.mkdir(brozima_ensembl_eqtl_out_dir)\n",
    "    starts = sorted(list(starts))\n",
    "    ends = sorted(list(ends))\n",
    "    for i in range(8):\n",
    "        start = starts[i]\n",
    "        end = ends[i]\n",
    "        mean_pred = np.stack(brozima_ensembl_dict[i]).mean(0)\n",
    "        np.save(os.path.join(brozima_ensembl_eqtl_out_dir,f'{score_type}_scores_{start}_{end}'), mean_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
